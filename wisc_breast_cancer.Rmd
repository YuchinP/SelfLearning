---
title: "Wisconsin Breast Cancer - Nearest Neighbor Approach"
author: "Yuchin Pan"
date: "January 14, 2017"
output: html_document
---
## Collecting and Exploring Data
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r Wisconsin Breast Cancer, include = TRUE}
wbcd <- read.csv("Machine-Learning-with-R-datasets-master/wisc_bc_data.csv", stringsAsFactors = FALSE)
str(wdbc)
```

We do not need the ID feature, we will need to remove it so it doesn't factor into the model's predictions

```{r}
wbcd <- wbcd[-1]
```

Diagnosis is of particular interest to us as it is what we want to predict from the model.
Many R machine learning classifiers require our target feature to be a factor so we will do that and add labels to it

```{r}
table(wbcd$diagnosis)
```
```{r}
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"), labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
```

Every other variable is numeric so let's look at a summary of a few features and more specifically a few of the means

```{r}
summary(wbcd)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
```

### Normalizing and Transforming the Data

area_mean will have a big impact for the smoothness in our distance calculation so we will need to do some normalization
Let's create a normalize function that implements a min-max normalization

```{r}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

#Test it out
normalize(c(1,2,3,4,5))
normalize(c(10,20,30,40,50))
```

In order to apply this function to a vector we'll need to use the **lapply()** function. It takes a list and applies a function to each element of the list. We will then convert the returned list into a datafram using the as.data.frame function

```{r}
#We use 2:31 because we don't want this function to apply to the non-numeric catagory Diagnosis
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
```

## Data Preparation - Creating Training and Test Datasets

We don't want to use the entire dataset for our model or we risk overfitting. We also want to be able to apply unknown results to our model and see how well it performs. We will split the data since we don't have any incoming new data. We will remove 100 for test data and use the rest for training.

```{r}
wbcd_train <- wbcd_n[1:469,]
wbcd_test <- wbcd_n[470:569,]
```

> When constructing test/training data it's important to remember each set is supposed to fully represent the data. These records are already randomized so we were allowed to just take 100 out. If this was ordered in a non-random pattern then we would need to implement random sampling

We removed the Diagnosis tareget variable when we constructed these datasets, we will need to store them into factor vectors divided to the test and training datasets

```{r}
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
```

## Training a Model on the Data

Because we're doing a kNN algorithm we don't have any model building. For a lazy learner like kNN we simply store the input data in a structured format. 

To classify our test instances, we use the implementation from the *class* package where we will use the **knn()** function. 
For each instance within the test data it will track the Euclidean distance based on our user-inputted "k". The test instance are classified by votes of the k-nearest neighbors based on the majority. Ties are broken at random.

> p <- knn(train, test, class, k)

A good rule of thumb is to use the square root of our training examples which is roughly 21.

```{r}
library("class")
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k = 21)
```

## Evaluating Model Performance

We want to test the model using the diagnosis in `wbcd_test_labels` vector. We will use the **CrossTable()** from the *gmodels* package.

```{r}
library("gmodels")
#We do not need the chisq values so we set it to FALSE
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq = FALSE)
```

> Our Top Left corner is our True Negatives. Top Right is False Positives. Bottom Left is False Negatives. Bottom Right is True Positives.

Based on our model we correctly identified 77 cases of benign mass. 21 cases where our model correctly identified the mass as malignant. Finally our model predicted 2 cases as Benign, but they were actually Malignant which is incredibly costly. Our model has an overall rate of 98% prediction accuracy.

## Improving Model Performance

To adjust we will try to do two simple variations. 
First we will employ an alternative rescaling for our numeric features
Second we will try several different k values

### Transforming with z-scores

While normalization is standard for kNN classification due to the nature of cancer z-scores might be better. It does not require a max or a min. This can be good as tumors can grow uncontrollably and have incredibly high outliers, which makes sense to have them weighted more heavily in this case. 

To standardize a vector we can use R's **scale()** function which will rescale values using z-score standardization. It can also be applied directly to a dataframe so **lapply** is unnecessary. 

```{r}
wbcd_z <- as.data.frame(scale(wbcd[-1]))
summary(wbcd_z$area_mean)
```

The mean of a z-score transformation should always be 0 and there should always be a relatively small range.
Z-scores over 3 or below -3 are an extremely rare value.

Now we need to repeat our previous sets with our newly transformed data

```{r}
wbcd_train_z <- wbcd_z[1:469,]
wbcd_test_z <- wbcd_z[470:569,]
wbcd_train_labels_z <- wbcd[1:469,1]
wbcd_test_labels_z <- wbcd[470:569,1]
wbcd_test_pred_z <- knn(train = wbcd_train_z, test = wbcd_test_z, cl = wbcd_train_labels_z, k = 21)
CrossTable(x = wbcd_test_labels_z, y = wbcd_test_pred_z, prop.chisq = FALSE)
```

Unfortunately changing our transformation to z-scores had no effect overall on our overall results as we still have 2 False Negatives. 

### Testing alternative values of k

After testing several different k values with different results I settled on k = 10

```{r}
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k = 10)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq = FALSE)
```

I was able to get this model has 1 False Positive, but 0 False Negatives raising our overall prediction accuracy of 99%. It may not show as the results change when I render this which leads me to the next point.

One must be careful with this though. It's dangerous to play with k-values too much as it may lead to an overfitting of a model. This is the case as another random sample of patients may differ greatly as seen below with the exact same k-value.

```{r}
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k = 10)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq = FALSE)
```