---
title: "dplyr"
author: "Yuchin Stone Pan"
date: "February 20, 2018"
output: html_document
---


This is an introduction to using dplyr. Very infrequently do we receive data in the correct format we need to create visualizations from. 
Often we will need to rename variables, create new ones, re-order observations, or any kind of transformation that will make it more digestible to work with.

We will do this learning the dyplr package and a new dataset on flights departing NYC in 2013.

```
library(nycflights13)
library(tidyverse)
```

We'll start by exploring the dataset


```
flights
```

This will output the first 10 of 33,776 rows and 10 of 19 columns. This is called a Tibble, a dataframe tweaked to work better in the tidyverse.

The various data types for reference
  int =  integer
  dbl = doubles or real numbers
  chr = character vectors or strings
  dttm = date-times
  
  lgl = logical (true or false)
  fctr = factor, categorical variables with fixed possible values (green, yellow, red)
  date = dates
  
## 5 keys

There are 5 key dplyr functions we will learn that will cover most of the data manipulation
  Pick observations by their values *Filter()*
  Reorder the rows *arrange()*
  Pick variables by their name *select()*
  Create new variables with functions of existing variables *Mutate()*
  Collapse many values down to a single summary *Summarize()*
  
These can all be used in conjunction with group_by() which changes the scope of each function from operating on the entire dataset to operating on it group-by-group. These 6 functions provide the verbs for data manipulation.

All verbs work similarly:
  1. The first argument is a data frame
  2. The subsequent arguments describe what to do with the data frame, using the variable names
  3. The result is a new data frame
  
### Filter
Filter allows us to subset observations based on their values.

For example we want o see all flights on January 1st.
```
filter(flights, month == 1, day == 1)
```
This returns the result, but if we want to continue using it we need to save it to a variable.

```
jan1 <- filter(flights, month == 1, day == 1)
```

If you want execute AND assign a variable wrap it all in parenthesis.

```
(dec25 <- filter(flights, month == 12, day == 25))
```

#### Comparisons
To use filtering effectively, you have to know how to select the observations that you want using the comparison operatiors. R provides the usual
  >
  >=
  <
  <=
  != not equal
  == equal
  
  Remember every number you see when using R is an approximation. Instead of relying on ==, use *near()*
  
#### Logical Operators
Multiple arguments to filter() are combined "and"
  Every expression must be true in order for a row to be included in the output
  
For other types of combinations you'll us
  & = and
  | = or
  ! = not

All flights in either Novemeber or December
```
filter(flights, month == 11 | month == 12)
```
More likely we want to us the in

```
nov_dec <- filter(flights, month %in% c(11,12))
nov_dec
```

#### Missing Values

One thing that will make running functions tough are missing values or NAs

In order to find out if a value is missing we use *is.na()*

filter() only includes rows where the condition is TRUE, excluding both FALSE and NA values.
  However if we want to keep them explicitly put them in.
  
```
df <- tibble(x = c(1,NA,3))
filter(df, x>1)

filter(df, is.na(x) | x >1)
```
#### Arrange Rows with arrange()
Arrange is similar to filter except instead of selecting rows, it changes the order.

It requires a data frame and a set of column names. 

```
arrange(flights, year, month, day)
```

On the other hand you can use desc to order in descending order.

```
arrange(flights, desc(arr_delay))
```

Missing values will always be sorted at the end

```
df <- tibble(x = c(5,2,NA))
arrange(df,x)
arrange(df, desc(x))
```

```
arrange(df, desc(is.na(x)))

arrange(flights, desc(dep_delay))
arrange(flights, dep_time)

arrange(flights, air_time)

arrange(flights, desc(distance))
arrange(flights, distance)
```

#### Select Columns with select()
Select allows you to find a subset of data. 

```
select(flights, year, month, day)

select(flights, year:day)

select(flights, -(year:day))

select(flights, starts_with("abc"))

select(flights, ends_with("xyz"))

select(flights, contains"ijk")

select(flights, "(.)\\1")

select(flights, num_range("x", 1:3))
```

Select can also be used to rename variables, but it drops all the variables not explicitly mentioned. rename()

A good way to get the rest of the columns is to use everything()

```
select(flights, month, month)
```

#### Add New Variables with mutate()
Mutate() always add new columns at the end of the dataset. 

```
flights_small <- select(flights,
year:day, ends_with("delay"),
distance,
air_time
)

mutate(flights_small,
gain = arr_delay - dep_delay,
speed = distance / air_time*60)
```

Note: If you only want to keep the new variables use transmute()

Modular Arithmatic
(%/% and %%)
%/% = integer division
%% = remainder

```
transmute(flights,
dep_time,
hour = dep_time %/% 100,
minute = dep_time %% 100)
```
R provides functions for running sums, products, mins and maxesL
  cumsum()
  cumprod()
  cummin()
  cummax()
  
  
#### Summarize
Summarize collapses a data frame to a single row.

```
summarize(flights, delay = mean(dep_delay, na.rm = TRUE))
```
This is not terribly useful unless we group this by a factor. This will change it from summarizing the whole dataset to a various groups of the dataset.

```
by_day <- group_by(flights, year, month, day)
summarize(by_day, delay = mean(dep_delay, na.rm= TRUE))
```

#### Combining Multiple Operations with the Pipe
Imagine that we want to explore the relationship between the distance and average delay for each location.

```
by_dest <- group_by(flights, dest)
delay <- summarize(by_dest,
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count > 20, dest != "HNL")

#It looks like delays increase with distance up to 750 miles and then decrease. 
#Maybe as flights get longer there's more ability to make up delays in the air

ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = FALSE)

#geom_smooth() using method = 'loess
```

The three steps that went through for this.
1. Group Flights by destination
2. Summarize to compute distance, average delay, and number of flights
3. Filter to remove noisy points and Honolulu airport, which is twice as far as the next airport

Another way to tackle the same problem!

```
delays <- flights %>%
  group_by(dest) %>%
  summarize(
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
  ) %>%
  filter(count > 20, dest != "HNL")
```

This focuses on the transformations, not what's being transformed, which makes it easier to read. 
You can read it as a series of imperative statements: group, then summarize, then filter. 

A good way to pronounce %>% when reading code is "then"

Behind the scenes x %>% f(y) turns into f(x,y), and x %>% f(y) %>% g(z) turns into g(f(x,y),z), and so on. You can use the pipe to rewrite multiple operations in a way you can read left to right, top to bottom.

#### Missing Values

What happens if we do not use the na.rm() argument.

```
flights %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay))
```

If there's any missing values in a aggregate function then the output will be missing values.

```
flights %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay, na.rm = TRUE))
```

In this case missing values represent cancelled flights. We could instead remove the cancelled flights first.

```
not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay))
```

#### Counts 
Whenever you do any aggregation, it's always a good idea to include either a count (n()), or a count of non missing values (sum(is.na(x))). That way you can check that you're not drawing conclusions based on very small amounts of data.

```
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay)
  )
  
  ggplot(data = delays, mapping = aes(x = delay)) +
    geom_freqpoly(binwidth = 10)
```
  
We can get more insight if we draw a scatter plot of number of flights versus average delay:

```
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )
  
ggplot(data = delays, mapping = aes(x = n, y = delay)) +
  geom_point(alpha = 1/10)
  )
```

Following shows a handy pattern for integrating ggplot2 into dplyr.
Filter out some of the smaller groups to get a better idea of the pattern and less of the extreme variation.

```
delays %>%
  filter(n > 25) %>%
  ggplot(mapping = aes(x = n, y = delay)) +
    geom_point(alpha = 1/10)
```

Another common variation of this type of pattern.
Looking at the average performance of batters in baseball is related to the number of tiumes they're at bat. Here we use the Lahman package to computer batting average of every MLB player.

When the skill of the batter is measured against the number of opportunities to hit the ball two patterns become apparent.

1. The variation in our aggregate decreases as we get more data points
2. There's a positive correlation between skill and opportunities to hit the ball. This is because teams control who gets to play, and obviously they'll pick their best players.

```
#convert to a tibble so it prints nicely
library(Lahman)
batting <- as_tibble(Lahman::Batting)

batters <- batting %>%
  group_by(playerID) %>%
  summarize(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    ab = sum(AB, na.rm = TRUE)
  )

batters %>%
  filter(ab > 100) %>%
  ggplot(mapping = aes(x = ab, y = ba)) +
    geom_point() +
    geom_smooth(se = FALSE)
#> geom_smooth() using method = gam
```
This also has important implications for ranking. If you naively sort on desc(ba) the people with the best batting averages are clearly lucky, not skilled.

```
batters %>%
  arrange(desc(ba))


batters %>%
  filter(ab > 10) %>%
  arrange(desc(ba))
```

#### Useful Summary functions
It's sometimes useful to combine aggregation with logical sub-setting. We haven't talked about this sort of subsetting yet,

```
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    #average delay
    avg_delay1 = mean(arr_delay),
    # average positive delay:
    avg_delay2 = mean(arr_delay[arr_delay >0])
    )
```

Measures of Spread
```
not_cancelled %>%
  group_by(dest) %>%
  summarize(distance_sd = sd(distance)) %>%
  arrange(desc(distance_sd))
```

Measures of Rank
```
not_cancelled %>%
  group_by(year,month, day) %>%
  summarize(
    first = min(dep_time),
    last = max(dep_time)
  )
```

Measures of Position
Getting the first and last departure for each day
```
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    first_dep = first(dep_time),
    last_dep = last(dep_time)
  )
```

These functions are complementary to filtering on ranks. Filtering gives you all variables, with each observation in a seperate row:

```
  not_cancelled %>%
    group_by(year, month, day) %>%
    mutate(r = min_rank(desc(dep_time))) %>%
    filter(r %in% range(r))
```

Counts n()
n() takes no arguments, and returns the size of the current group. To count the number of non-missing value, use sum(!is.na(x)). To count the number of distinct (unique) values, use n_distinct(x):

```
#which destinations have the most carriers?
not_cancelled %>%
  group_by(dest) %>%
  summarize(carriers = n_distinct(carrier)) %>%
  arrange(desc(carriers))
```

count is useful just to give you an idea of a dataset
```
not_cancelled %>%
  count(tailnum, wt = distance)
```

Counts and proportions of logical values

```
#how many flights left before 5am? usually indicate delayed flights from previous day
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(n_early = sum(dep_time < 500))

#What proportion of flights are delayed by more than an hour

not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(hour_perc = mean(arr_delay > 60))
```

#### Grouping by Multiple Variables

When you group by multiple variables, each summary peels off one level of the grouping. That makes it easy to progressively roll up a dataset.

```
daily <- group_by(flights, year, month, day)
(per_day <- summarize(daily, flights = n()))

(per_month <- summarize(per_day, flights = sum(flights)))

(per_year <- summarize(per_month, flights = sum(flights)))
```

#### Grouped Mutates (and Filters)

Grouping is most useful in conjuction with summarize(), but you can also do operations with mutate and filter.

Find the worst members of each group

```
flights_small %>%
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

Find all groups bigger than a threshold
```
popular_dest <- flights %>%
  group_by(dest) %>%
  filter(n() > 365)
popular_dest
```

Standardize to compute per group metrics
```
popular_dest %>%
  filter(arr_delay > 0) %>%
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
  select(year:day, dest, arr_delay, prop_delay)
```

A grouped filter is a grouped mutate followed by an ungrouped filter. Generally good to avoid except for quick and dirty manipulations. 

Functions that work best in grouped mutates and filters are known as window functions. 
    
