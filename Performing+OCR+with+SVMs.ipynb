{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing OCR with SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image processing is a difficult task for many types of machine learning algorithms. The relationships linking patterns of pixels to higher concepts are extremely complex and hard to define. It's easy for a human to recognize a face, a cat, or the letter A, but defining these patterns in strict rules is difficult. Furthermore, image data is usually very noisy. Depending on lighting, orientation or positioning it can be very hard to tell.\n",
    "\n",
    "SVMs are well-suited for tackling image data. Capable of learning complex patterns without being overly sensitive to noise, they are able to recognize visual patterns with a high degree of accuracy.\n",
    "\n",
    "Moreover, the key weakness of SVMs - The Black Box model representation - is less critical for image processing. If it can detect the difference between a cat and a dog, how it does it doesn't matter as much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When OCR software first processes a document, it divides the paper into a matrix such that each cell in the grid contains a single glyph. Next it will try to match the glyph to all characters it recognizes. Finally it'll all be combined back together for words, which optionally could be spell-checked against a dictionary in the document's language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using data from the UCI Machine Learning Data Repository, containing 20,000 examples of 26 english alphabet capital letters printed using 20 different randomly reshaped and distorted black and white fonts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters <- read.csv(\"C:/Users/Yuchi/Downloads/letter-recognition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t20000 obs. of  17 variables:\n",
      " $ Letter: Factor w/ 26 levels \"A\",\"B\",\"C\",\"D\",..: 20 9 4 14 7 19 2 1 10 13 ...\n",
      " $ X.box : int  2 5 4 7 2 4 4 1 2 11 ...\n",
      " $ Y.box : int  8 12 11 11 1 11 2 1 2 15 ...\n",
      " $ width : int  3 3 6 6 3 5 5 3 4 13 ...\n",
      " $ high  : int  5 7 8 6 1 8 4 2 4 9 ...\n",
      " $ onpix : int  1 2 6 3 1 3 4 1 2 7 ...\n",
      " $ X.bar : int  8 10 10 5 8 8 8 8 10 13 ...\n",
      " $ Y.bar : int  13 5 6 9 6 8 7 2 6 2 ...\n",
      " $ x2bar : int  0 5 2 4 6 6 6 2 2 6 ...\n",
      " $ y2bar : int  6 4 6 6 6 9 6 2 6 2 ...\n",
      " $ xybar : int  6 13 10 4 6 5 7 8 12 12 ...\n",
      " $ x2ybr : int  10 3 3 4 5 6 6 2 4 1 ...\n",
      " $ xy2br : int  8 9 7 10 9 6 6 8 8 9 ...\n",
      " $ X.ege : int  0 2 3 6 1 0 2 1 1 8 ...\n",
      " $ xegvy : int  8 8 7 10 7 8 8 6 6 1 ...\n",
      " $ Y.ege : int  0 4 3 2 5 9 7 2 1 1 ...\n",
      " $ yegvx : int  8 10 9 8 10 7 10 7 7 8 ...\n"
     ]
    }
   ],
   "source": [
    "str(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: SVM Learners require all features to be numeric, and moreover, that each feature is scaled to a fairly small interval. Every feature in this case is an int, so we don't have to convert anything. On the other hand some of the ranges are fairly wide. This suggest we probably need to normalize or standardize the data. However the package we'll be using for this will do this for us automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would usually create a random section fro training and testing data sets, but in this data set it has already been randomized and would suggest using the first 16,000 for building the model and the next 4,000 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters_train <- letters[1:16000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters_test <- letters[16001:20000,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of SVM packages to use. The **e1071** package provides an R interface to the LIBSVM library, a widely-used open source SVM program. \n",
    "If you're already invested in the SVMlight algorithm, the **klaR** package provides functions to work with this SVM implementation directely from R.\n",
    "Finally, if you're starting from scratch, it might be worth starting with the functions in the **kernlab** package. This was developed natively within R rather than C or C++ which alows it to be easily customized. Most importantly, **kernlab** can be used with the **caret** package, which allows SVM models to be trained and evaluated using a variety of automated methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/yuchi/Documents/R/win-library/3.4'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'kernlab' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\yuchi\\AppData\\Local\\Temp\\RtmpEdmCxt\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"kernlab\", repos = \"http://cran.us.r-project.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(kernlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are calling the *ksvm* function on the training data and specify the linear(that is,vanilla) kernal using the *vanilladot* option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    }
   ],
   "source": [
    "letter_classifier <- ksvm(Letter ~ ., data = letters_train, kernel = \"vanilladot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Support Vector Machine object of class \"ksvm\" \n",
       "\n",
       "SV type: C-svc  (classification) \n",
       " parameter : cost C = 1 \n",
       "\n",
       "Linear (vanilla) kernel function. \n",
       "\n",
       "Number of Support Vectors : 7039 \n",
       "\n",
       "Objective Function Value : -14.1747 -20.007 -23.5629 -6.2007 -7.5523 -32.7693 -49.9788 -18.1824 -62.111 -32.7284 -16.221 -32.2839 -28.9776 -51.2192 -13.276 -35.6223 -30.8612 -16.5255 -14.681 -32.7472 -30.3216 -7.7959 -11.814 -32.3455 -13.126 -9.2693 -153.165 -52.9678 -76.7743 -119.2073 -165.4435 -54.6247 -41.9818 -67.2686 -25.1959 -27.6368 -26.41 -35.5578 -41.26 -122.1636 -187.9174 -222.0861 -21.4765 -10.3749 -56.3682 -12.2279 -49.4902 -9.3371 -19.2099 -11.1776 -100.2194 -29.14 -238.0507 -77.1985 -8.334 -4.5309 -139.8544 -80.8849 -20.3643 -13.0243 -82.515 -14.5037 -26.7516 -18.5709 -23.9512 -27.3041 -53.273 -11.4773 -5.1202 -13.9501 -4.4981 -3.5754 -8.4912 -40.971 -49.8188 -190.0265 -43.8604 -44.868 -45.258 -13.5555 -17.767 -87.4103 -107.1064 -37.025 -30.713 -112.3208 -32.9635 -27.2966 -35.5832 -17.8585 -5.1394 -43.4089 -7.7841 -16.6797 -58.51 -159.9932 -49.0779 -37.8439 -32.801 -74.5254 -133.3417 -11.164 -5.3575 -12.4375 -30.9902 -141.6928 -54.2953 -179.012 -99.8894 -10.288 -15.1555 -3.7818 -67.612 -7.6958 -88.9304 -47.6447 -94.3718 -70.2735 -71.5066 -21.7856 -12.7654 -7.4383 -23.5023 -13.1052 -239.9699 -30.4194 -25.211 -136.2793 -140.9563 -9.812 -34.4584 -6.304 -60.8422 -66.5785 -27.282 -214.3225 -34.7801 -16.7631 -135.7818 -160.627 -45.2949 -25.1021 -144.9052 -82.2355 -327.7157 -142.0611 -158.8819 -32.2184 -32.8889 -52.9638 -25.4942 -47.9924 -6.8991 -9.7296 -36.4361 -70.3911 -187.7606 -46.9366 -89.8108 -143.4214 -624.3642 -119.2205 -145.4432 -327.7745 -33.3256 -64.0603 -145.4829 -116.5903 -36.2988 -66.3768 -44.8241 -7.509 -217.9246 -12.971 -30.5035 -2.0371 -6.1261 -14.4445 -21.6334 -57.3084 -20.6923 -184.3623 -20.105 -4.1485 -4.5347 -0.8281 -121.4429 -7.9484 -58.5602 -21.4882 -13.5474 -5.6465 -15.6294 -28.9573 -20.5961 -76.7112 -27.0123 -94.7105 -15.1714 -10.0223 -7.6397 -1.5785 -87.6952 -6.2237 -99.3707 -101.0906 -45.6639 -24.0721 -61.7692 -24.1578 -52.2364 -234.326 -39.9757 -48.8561 -34.1458 -20.9665 -11.4524 -123.0291 -6.4901 -5.1868 -8.8018 -9.4612 -21.7736 -24.2361 -123.3978 -31.4396 -88.3897 -30.0912 -13.8194 -9.2701 -3.0825 -87.9616 -6.3842 -13.9679 -65.0712 -105.5232 -13.7404 -13.7627 -50.4226 -2.9331 -8.429 -80.9508 -36.4142 -112.7479 -4.1714 -7.8989 -1.2678 -90.8033 -21.4921 -7.2235 -47.9551 -3.3832 -20.433 -64.6126 -45.5778 -56.1314 -6.1347 -18.6305 -2.3742 -72.2553 -111.188 -106.765 -23.1321 -19.3763 -54.9815 -34.2944 -64.4748 -20.4109 -6.6886 -4.3781 -59.1414 -34.2461 -58.1506 -33.8664 -10.6902 -53.1394 -13.7482 -20.1987 -55.092 -3.8058 -60.0373 -235.484 -12.6837 -11.7408 -17.3059 -9.7171 -65.8491 -17.1047 -42.8136 -53.1058 -25.0432 -15.3018 -44.0747 -16.9584 -62.9777 -5.2037 -5.2966 -86.1709 -3.7209 -6.3449 -1.1265 -122.5773 -23.904 -355.0149 -31.1009 -32.6198 -4.9668 -84.1037 -134.5943 -72.8374 -23.9003 -35.5893 -11.7117 -22.2889 -1.8598 -59.2178 -8.8997 -150.7441 -1.8536 -1.9713 -9.9677 -0.5208 -26.9227 -30.4291 -5.6286 \n",
       "Training error : 0.13025 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letter_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This info tells us very little about how well the model will perform in the real world. We'll need to examine it's performance on the testing dataset to know whether it generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *predict()* function allows us to use the letter classification model to make predictions on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letter_predictions <- predict(letter_classifier, letters_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we didn't specify the type parameter, the default type = \"response\" was used. This returns a vector containing a predicted letter for each row of values in the testing data. Using the *Head()* function, we can see that the first six predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>U</li>\n",
       "\t<li>N</li>\n",
       "\t<li>V</li>\n",
       "\t<li>X</li>\n",
       "\t<li>N</li>\n",
       "\t<li>H</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item U\n",
       "\\item N\n",
       "\\item V\n",
       "\\item X\n",
       "\\item N\n",
       "\\item H\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. U\n",
       "2. N\n",
       "3. V\n",
       "4. X\n",
       "5. N\n",
       "6. H\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] U N V X N H\n",
       "Levels: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(letter_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to examine how well our classifier performed, we need to compare the predicted letter to the true letter in the testing dataset. We'll use *table()* function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  \n",
       "letter_predictions   A   B   C   D   E   F   G   H   I   J   K   L   M   N   O\n",
       "                 A 144   0   0   0   0   0   0   0   0   1   0   0   1   2   2\n",
       "                 B   0 121   0   5   2   0   1   2   0   0   1   0   1   0   0\n",
       "                 C   0   0 120   0   4   0  10   2   2   0   1   3   0   0   2\n",
       "                 D   2   2   0 156   0   1   3  10   4   3   4   3   0   5   5\n",
       "                 E   0   0   5   0 127   3   1   1   0   0   3   4   0   0   0\n",
       "                 F   0   0   0   0   0 138   2   2   6   0   0   0   0   0   0\n",
       "                 G   1   1   2   1   9   2 123   2   0   0   1   2   1   0   1\n",
       "                 H   0   0   0   1   0   1   0 102   0   2   3   2   3   4  20\n",
       "                 I   0   1   0   0   0   1   0   0 141   8   0   0   0   0   0\n",
       "                 J   0   1   0   0   0   1   0   2   5 128   0   0   0   0   1\n",
       "                 K   1   1   9   0   0   0   2   5   0   0 118   0   0   2   0\n",
       "                 L   0   0   0   0   2   0   1   1   0   0   0 133   0   0   0\n",
       "                 M   0   0   1   1   0   0   1   1   0   0   0   0 135   4   0\n",
       "                 N   0   0   0   0   0   1   0   1   0   0   0   0   0 145   0\n",
       "                 O   1   0   2   1   0   0   1   2   0   1   0   0   0   1  99\n",
       "                 P   0   0   0   1   0   2   1   0   0   0   0   0   0   0   2\n",
       "                 Q   0   0   0   0   0   0   8   2   0   0   0   3   0   0   3\n",
       "                 R   0   7   0   0   1   0   3   8   0   0  13   0   0   1   1\n",
       "                 S   1   1   0   0   1   0   3   0   1   1   0   1   0   0   0\n",
       "                 T   0   0   0   0   3   2   0   0   0   0   1   0   0   0   0\n",
       "                 U   1   0   3   1   0   0   0   2   0   0   0   0   0   0   1\n",
       "                 V   0   0   0   0   0   1   3   4   0   0   0   0   1   2   1\n",
       "                 W   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0\n",
       "                 X   0   1   0   0   2   0   0   1   3   0   1   6   0   0   1\n",
       "                 Y   3   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "                 Z   2   0   0   0   1   0   0   0   3   4   0   0   0   0   0\n",
       "                  \n",
       "letter_predictions   P   Q   R   S   T   U   V   W   X   Y   Z\n",
       "                 A   0   5   0   1   1   1   0   1   0   0   1\n",
       "                 B   2   2   3   5   0   0   2   0   1   0   0\n",
       "                 C   0   0   0   0   0   0   0   0   0   0   0\n",
       "                 D   3   1   4   0   0   0   0   0   3   3   1\n",
       "                 E   0   2   0  10   0   0   0   0   2   0   3\n",
       "                 F  16   0   0   3   0   0   1   0   1   2   0\n",
       "                 G   2   8   2   4   3   0   0   0   1   0   0\n",
       "                 H   0   2   3   0   3   0   2   0   0   1   0\n",
       "                 I   1   0   0   3   0   0   0   0   5   1   1\n",
       "                 J   1   3   0   2   0   0   0   0   1   0   6\n",
       "                 K   1   0   7   0   1   3   0   0   5   0   0\n",
       "                 L   0   1   0   5   0   0   0   0   0   0   1\n",
       "                 M   0   0   0   0   0   3   0   8   0   0   0\n",
       "                 N   0   0   3   0   0   1   0   2   0   0   0\n",
       "                 O   3   3   0   0   0   3   0   0   0   0   0\n",
       "                 P 130   0   0   0   0   0   0   0   0   1   0\n",
       "                 Q   1 124   0   5   0   0   0   0   0   2   0\n",
       "                 R   1   0 138   0   1   0   1   0   0   0   0\n",
       "                 S   0  14   0 101   3   0   0   0   2   0  10\n",
       "                 T   0   0   0   3 133   1   0   0   0   2   2\n",
       "                 U   0   0   0   0   0 152   0   0   1   1   0\n",
       "                 V   0   3   1   0   0   0 126   1   0   4   0\n",
       "                 W   0   0   0   0   0   4   4 127   0   0   0\n",
       "                 X   0   0   0   1   0   0   0   0 137   1   1\n",
       "                 Y   7   0   0   0   3   0   0   0   0 127   0\n",
       "                 Z   0   0   0  18   3   0   0   0   0   0 132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(letter_predictions, letters_test$Letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal values indicate the total number of records where the predicted letter matches the true value. Similarly, the number of mistakes is also listed. For example, the value 5 in the row B and column D indicates there were 5 cases where the letter D was mistaked as a B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simplify our evaluation by instead calculating overall accuracy. This considers only whether the prediction was correct or incorrect and ignores the type of error. The following command returns a vector of TRUE or FALSE values indicating whether the model's predicted letter agrees with the actual letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement <- letter_predictions == letters_test$Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement\n",
       "FALSE  TRUE \n",
       "  643  3357 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement\n",
       "  FALSE    TRUE \n",
       "0.16075 0.83925 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop.table(table(agreement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About an 84% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous model used the simple linear kernal function. By using a more complex kernal, we can map the data into a higher dimensional space and potentially obtain a better model fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty challenging to choose which one from the many options. A popular convention is to begin with the Gaussian RBF kernal, which has been shown to perform well for many types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letter_classifier_rbf <- ksvm(Letter ~ ., data = letters_train, kernel = \"rbfdot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions similar to before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letter_predictions_rbf <- predict(letter_classifier_rbf, letters_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing accuracy to our linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agreement_rbf <- letter_predictions_rbf == letters_test$Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement_rbf\n",
       "FALSE  TRUE \n",
       "  281  3719 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(agreement_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement_rbf\n",
       "  FALSE    TRUE \n",
       "0.07025 0.92975 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop.table(table(agreement_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By just changing the kernel function, we were able to increase the accuracy of our character recognition model from 84% to 93%. If this accuracy is still not good enough for the OCR, other kernels could be tested or the COST could be varied to modify the width of the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      \n",
       "letter_predictions_rbf   A   B   C   D   E   F   G   H   I   J   K   L   M   N\n",
       "                     A 151   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "                     B   0 127   0   3   0   1   0   2   0   0   0   1   2   1\n",
       "                     C   0   0 132   0   3   0   1   0   2   0   0   1   0   0\n",
       "                     D   1   1   0 161   0   0   2   9   2   3   1   0   0   1\n",
       "                     E   0   0   3   0 137   2   0   0   0   1   0   4   0   0\n",
       "                     F   0   0   0   0   0 148   0   0   3   0   0   0   0   0\n",
       "                     G   0   0   2   0   8   0 155   2   0   0   0   2   2   0\n",
       "                     H   0   1   0   1   0   0   1 124   0   1   2   1   1   3\n",
       "                     I   0   0   0   0   0   0   0   0 151   3   0   0   0   0\n",
       "                     J   0   0   0   0   0   0   0   0   3 136   0   0   0   0\n",
       "                     K   0   0   1   0   0   0   0   5   0   0 132   0   0   1\n",
       "                     L   0   0   0   0   0   0   1   0   0   0   0 141   0   0\n",
       "                     M   0   0   0   0   0   0   1   1   0   0   0   0 138   1\n",
       "                     N   0   0   0   0   0   2   0   0   0   0   0   0   0 150\n",
       "                     O   0   0   2   0   0   0   0   0   0   1   0   0   0   5\n",
       "                     P   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "                     Q   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
       "                     R   0   4   1   1   0   0   2   5   0   0   9   1   0   3\n",
       "                     S   0   2   0   0   0   0   0   0   1   2   0   2   0   0\n",
       "                     T   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "                     U   0   0   1   1   0   0   0   1   0   0   0   0   0   0\n",
       "                     V   0   0   0   0   0   0   0   0   0   0   0   0   1   1\n",
       "                     W   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "                     X   0   1   0   0   1   0   0   0   0   0   2   4   0   0\n",
       "                     Y   4   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
       "                     Z   0   0   0   0   3   0   0   0   2   1   0   0   0   0\n",
       "                      \n",
       "letter_predictions_rbf   O   P   Q   R   S   T   U   V   W   X   Y   Z\n",
       "                     A   0   0   3   0   0   1   0   0   0   0   0   0\n",
       "                     B   0   2   1   3   3   0   0   4   1   1   0   0\n",
       "                     C   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "                     D   1   3   1   3   0   2   0   0   0   2   3   0\n",
       "                     E   0   1   0   0   2   1   0   0   0   0   0   2\n",
       "                     F   0  11   0   0   1   0   0   1   0   0   0   0\n",
       "                     G   2   1   0   0   0   2   0   0   0   0   0   0\n",
       "                     H   0   1   1   0   0   2   0   0   0   0   0   0\n",
       "                     I   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "                     J   0   0   0   0   0   0   0   0   0   0   0   3\n",
       "                     K   0   0   0   3   0   0   0   0   0   2   0   0\n",
       "                     L   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "                     M   0   0   0   0   0   0   1   0   2   0   0   0\n",
       "                     N   0   0   0   2   0   0   0   0   1   0   0   0\n",
       "                     O 129   2   4   0   0   0   1   0   0   0   0   0\n",
       "                     P   0 140   0   0   0   0   0   0   0   0   0   0\n",
       "                     Q   3   3 158   0   0   0   0   0   0   0   0   0\n",
       "                     R   2   1   0 150   0   1   0   0   0   0   0   0\n",
       "                     S   0   0   0   0 151   0   0   0   0   0   0   2\n",
       "                     T   0   0   0   0   1 140   0   0   0   0   1   0\n",
       "                     U   0   0   0   0   0   0 161   0   0   0   1   0\n",
       "                     V   0   0   0   0   0   0   2 131   0   0   1   0\n",
       "                     W   2   0   0   0   0   0   3   0 135   0   0   0\n",
       "                     X   0   0   0   0   1   1   0   0   0 153   1   1\n",
       "                     Y   0   3   0   0   0   1   0   0   0   0 138   0\n",
       "                     Z   0   0   0   0   1   0   0   0   0   0   0 150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(letter_predictions_rbf, letters_test$Letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking deeper, it looks like the biggest similar letters causing issues are D's getting mistaken for H's and especially F's being mistaken for P's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
